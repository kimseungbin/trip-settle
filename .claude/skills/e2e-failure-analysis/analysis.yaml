name: e2e-failure-analysis
description: |
  Analyze Playwright E2E test failures to quickly diagnose issues and provide fix recommendations.

  Use this skill to:
  - Identify which tests failed and why
  - Categorize failures by error type
  - Surface relevant debugging artifacts
  - Provide actionable fix recommendations
  - Help developers resolve test failures fast

instructions: |
  When the user requests E2E failure analysis or mentions failed E2E tests:

  ## Prerequisites: Git Notes Helper Skill

  This skill uses git notes extensively for historical analysis (Phase 3 features). Before starting:

  1. **Reference git-notes-helper skill** for common operations:
     - Read `.claude/skills/git-notes-helper/helper.yaml` for git notes operations
     - Use namespace: `ci/e2e-failures`
     - Follow patterns from git-notes-helper for fetching, parsing, and historical analysis

  2. **Key operations from git-notes-helper**:
     - Fetch notes: Operation 1
     - Check existence: Operation 2
     - Show note: Operation 3
     - List commits: Operation 4
     - Parse INI fields: Operation 5
     - Get commit context: Operation 6
     - Historical analysis: Operation 7
     - Compare commits: Operation 8

  ## Step 1: Check for CI Failure Metadata (Git Notes)

  **NEW in Phase 2**: E2E test failures from CI are automatically captured in git notes.
  This is the FASTEST way to analyze CI failures without downloading artifacts.

  Use **git-notes-helper** Operations 1-3:

  ```bash
  # Operation 1: Fetch E2E failure notes from remote
  git fetch origin refs/notes/ci/e2e-failures:refs/notes/ci/e2e-failures 2>/dev/null || \
    echo "No E2E failure notes found (CI capture may not be set up yet)"

  # Operation 2: Check if notes exist
  git notes --ref=ci/e2e-failures show HEAD  # Current commit
  git notes --ref=ci/e2e-failures list | head -10  # All recent commits

  # Operation 3: Show note content
  git notes --ref=ci/e2e-failures show <commit-hash>
  ```

  **If notes exist**: Parse the INI-format data (see "Parse Git Notes" section below).
  **If notes don't exist**: Fall back to Step 2 (local test results).

  ### Parse Git Notes Format

  Git notes contain INI-format failure metadata. Use **git-notes-helper** Operation 5:

  **Reference**: See `.claude/skills/git-notes-helper/helper.yaml` ‚Üí Operation 5 (Parse INI Format Fields)

  ```bash
  # Extract top-level fields (Operation 5)
  git notes --ref=ci/e2e-failures show HEAD | grep "^total_tests" | cut -d'=' -f2 | xargs
  git notes --ref=ci/e2e-failures show HEAD | grep "^failed" | cut -d'=' -f2 | xargs

  # Get failure details from numbered sections (Operation 5)
  git notes --ref=ci/e2e-failures show HEAD | grep -A 8 "^\[failure\.1\]"

  # Count failure sections
  git notes --ref=ci/e2e-failures show HEAD | grep -c "^\[failure\."
  ```

  **Note structure**:
  - `[metadata]` - Timestamp, commit, run URL, test counts
  - `[summary]` - Status, failure counts by type
  - `[failure.N]` - Individual failure details (test name, error, artifacts)
  - `[diagnostics]` - Environment info

  **Advantages of git notes**:
  - No artifact download needed
  - Fast analysis (metadata already extracted)
  - Historical tracking (notes persist across commits)
  - Team-wide visibility (pushed to remote)

  ## Step 2: Locate Local Test Results (Fallback)

  If git notes unavailable, check local test results:

  ### Local Test Results (packages/frontend/test-results/)

  ```bash
  # Check if test results exist
  ls -la packages/frontend/test-results/

  # Look for JSON reporter output (most structured, preferred)
  find packages/frontend/test-results -name "*.json" -type f

  # Check for JUnit XML (alternative structured format)
  find packages/frontend/test-results -name "junit.xml" -type f
  ```

  ### Playwright HTML Report (packages/frontend/playwright-report/)

  ```bash
  # Check if HTML report exists
  ls -la packages/frontend/playwright-report/

  # HTML report is human-readable but harder to parse programmatically
  # Use as fallback if JSON unavailable
  ```

  ### GitHub Actions Artifacts (CI failures)

  If analyzing CI failures, artifacts are available via GitHub Actions:
  - Artifact name: `playwright-test-results` (test results JSON)
  - Artifact name: `playwright-report` (HTML report)
  - Retention: 30 days

  **Important**: For CI failures, prefer git notes (Step 1) over downloading artifacts.

  ## Step 3: Parse Test Results

  ### Method A: Parse JSON Reporter Output (Preferred)

  Playwright's JSON reporter generates structured failure data. Parse it to extract:

  ```bash
  # Example: Read results.json
  cat packages/frontend/test-results/results.json

  # Or read JUnit XML
  cat packages/frontend/test-results/junit.xml
  ```

  **Key data to extract**:
  - `test.title` - Test name
  - `test.file` - Test file path
  - `test.status` - passed/failed/skipped/flaky
  - `test.errors` - Error messages and stack traces
  - `test.attachments` - Screenshots, videos, traces
  - `test.projectName` - Browser (chromium, webkit, etc.)
  - `test.duration` - How long test ran

  ### Method B: Parse Console Output (Fallback)

  If structured output unavailable, parse console logs:

  ```bash
  # Example: Last test run output (if available)
  # Look for patterns like:
  # ‚úì ExpenseTracker ‚Ä∫ should add expense [chromium] (1.2s)
  # ‚úó ExpenseTracker ‚Ä∫ should delete expense [webkit] (5.0s)
  #
  #   Error: Timeout 5000ms exceeded.
  #   waiting for getByRole('button', { name: 'Delete' })
  ```

  ## Step 4: Categorize Failures

  Classify each failure by error type to provide targeted recommendations:

  ### Error Type Detection

  **Timeout Errors**:
  - Pattern: `Timeout.*exceeded`, `waiting for`, `locator.click: Timeout`
  - Cause: Element not found/visible/enabled within timeout
  - Common in: Element selection, animations, async operations

  **Assertion Failures**:
  - Pattern: `expect.*to.*`, `Expected.*Received`, `toBe`, `toHaveText`
  - Cause: Expected value doesn't match actual
  - Common in: State validation, content checks

  **Visual Regression Failures**:
  - Pattern: `toHaveScreenshot`, `Screenshot comparison failed`, `pixels differ`
  - Cause: UI appearance changed
  - Common in: CSS changes, layout shifts, font rendering

  **Navigation/Routing Errors**:
  - Pattern: `page.goto`, `Navigation failed`, `net::ERR_`
  - Cause: Page failed to load, network issues
  - Common in: Server down, incorrect URL, CORS

  **Setup/Teardown Errors**:
  - Pattern: `beforeEach`, `afterEach`, `beforeAll`, `afterAll`
  - Cause: Test fixture setup failed
  - Common in: Database setup, authentication, cleanup

  ## Step 5: Extract Artifact References

  For each failed test, identify available debugging artifacts:

  ### Artifact Types

  **Screenshots** (`.png` files):
  - Captured automatically on failure
  - Path pattern: `test-results/{test-name}-{browser}/test-failed-{n}.png`
  - Use: See exact UI state at failure moment

  **Videos** (`.webm` files):
  - Full test execution recording
  - Path pattern: `test-results/{test-name}-{browser}/video.webm`
  - Use: Watch test execution to understand failure context

  **Traces** (`.zip` files):
  - Playwright trace with full timeline, network, console
  - Path pattern: `test-results/{test-name}-{browser}/trace.zip`
  - Use: Deep debugging with Playwright Trace Viewer

  **Expected vs Actual Screenshots** (visual tests):
  - Expected: `*-expected.png`
  - Actual: `*-actual.png`
  - Diff: `*-diff.png`
  - Use: Compare visual changes pixel-by-pixel

  ## Step 6: Generate Failure Report

  Present findings in clear, actionable format:

  ### Report Template

  ```markdown
  === E2E TEST FAILURE ANALYSIS ===

  ## Summary
  - **Total Tests**: {total}
  - **Passed**: {passed} ‚úÖ
  - **Failed**: {failed} ‚ùå
  - **Pass Rate**: {pass_rate}%

  ## Failed Tests

  ### {n}. {test_name} [{browser}]
  **File**: `{test_file}:{line_number}`
  **Error Type**: {error_type}
  **Duration**: {duration}ms

  **Error Message**:
  ```
  {error_message}
  {stack_trace_excerpt}
  ```

  **Artifacts**:
  - üì∏ Screenshot: `{screenshot_path}`
  - üé• Video: `{video_path}`
  - üîç Trace: `{trace_path}`

  **Fix Recommendations**:
  {debugging_steps_based_on_error_type}

  ---

  ## Quick Fixes

  {summary_of_recommended_actions}

  ## Debugging Commands

  {commands_to_reproduce_locally}
  ```

  ### Debugging Recommendations by Error Type

  **Timeout Errors** ‚Üí Provide these steps:
  1. Check if element selector changed in recent commits
  2. Verify element is visible/enabled (not hidden by CSS)
  3. Check for race conditions (async state updates)
  4. Review component rendering logic
  5. Run test locally with `--debug` flag to step through
  6. Consider increasing timeout if legitimately slow operation

  **Assertion Failures** ‚Üí Provide these steps:
  1. Review expected vs actual values
  2. Check if business logic changed
  3. Verify test expectations are still valid
  4. Look for state management bugs
  5. Check for timing issues (async assertions)

  **Visual Regression Failures** ‚Üí Provide these steps:
  1. View diff image to see exact pixel changes
  2. Review CSS changes in recent commits (git diff *.css *.svelte)
  3. If change is intentional: Add `[update-snapshots]` to commit message
  4. If change is unintentional: Investigate CSS regression
  5. Check for font rendering differences (OS-specific)
  6. Verify snapshots are Linux-based (CI environment)

  **Navigation Errors** ‚Üí Provide these steps:
  1. Check if backend is running (docker-compose status)
  2. Verify URL configuration (baseURL in playwright.config.ts)
  3. Check for CORS issues (browser console)
  4. Review network tab in trace viewer
  5. Ensure test environment is properly set up

  ## Step 7: Provide Local Reproduction Steps

  Help user reproduce failures locally:

  ```bash
  # Run specific failed test
  npx playwright test {test_file} --project={browser}

  # Run with UI mode for interactive debugging
  npm run test:e2e:ui --workspace=frontend

  # Run with debug mode (Playwright Inspector)
  npm run test:e2e:debug --workspace=frontend

  # Run with headed mode (see browser)
  npx playwright test {test_file} --headed

  # Update visual snapshots (if visual regression)
  npm run test:e2e:docker:update-snapshots
  ```

  ## Step 8: Browser-Specific Analysis

  If failures occur in only one browser, highlight this:

  ```markdown
  ## Browser-Specific Failures ‚ö†Ô∏è

  The following tests fail only in **{browser}**:
  - {test_1}
  - {test_2}

  **Possible Causes**:
  - Browser-specific CSS rendering
  - Browser-specific JavaScript API differences
  - WebKit vs Chromium engine differences
  - Timing differences between browsers

  **Action**: Test specifically in {browser} locally to debug.
  ```

  ## Step 9: Advanced Analysis (Phase 3 Features)

  **NEW in Phase 3**: Analyze historical patterns across commits using git notes.

  ### Feature 1: Flaky Test Detection

  Identify tests that intermittently fail without code changes (unreliable tests).

  **Workflow** (uses **git-notes-helper** Operations 1, 4, 5, 7):

  **Reference**: See `.claude/skills/git-notes-helper/helper.yaml` ‚Üí Operation 7 (Historical Analysis)

  ```bash
  # Step 1: Fetch git notes (Operation 1)
  git fetch origin refs/notes/ci/e2e-failures:refs/notes/ci/e2e-failures

  # Step 2: Get recent commits with E2E notes (Operation 4 + 7)
  # Simplified approach (avoids complex while loops):
  git notes --ref=ci/e2e-failures list | head -20 | awk '{print $2}'

  # Step 3: For each commit, extract test pass/fail status (Operation 5)
  # Extract test names from note
  git notes --ref=ci/e2e-failures show <commit> | grep "^test_name" | cut -d'=' -f2

  # Step 4: Build pass/fail history for each unique test
  # Example: "ExpenseTracker ‚Ä∫ should add expense with Enter key"
  #   Commit 1: ‚úÖ (not in failures)
  #   Commit 2: ‚ùå (in [failure.1])
  #   Commit 3: ‚úÖ (not in failures)
  #   Commit 4: ‚ùå (in [failure.2])

  # Step 5: Calculate flakiness metrics
  # Flip rate = (number of status changes) / (total runs - 1)
  # Example: ‚úÖ ‚ùå ‚úÖ ‚ùå ‚úÖ = 4 flips / 4 transitions = 100% flip rate

  # Step 6: Identify flaky tests (flip rate > 30%)
  ```

  **Simplified Commands** (follow git-notes-helper best practices):

  ```bash
  # Get commit hashes with notes (Operation 4)
  git notes --ref=ci/e2e-failures list | head -10 | awk '{print $2}'

  # Extract all test names from a note (Operation 5)
  git notes --ref=ci/e2e-failures show <commit> | grep "^test_name" | cut -d'=' -f2

  # Check if specific test failed in a commit (Operation 5)
  git notes --ref=ci/e2e-failures show <commit> | grep -q "test_name = ExpenseTracker ‚Ä∫ should add expense"
  echo $?  # 0 = failed, 1 = passed
  ```

  **Flakiness Thresholds:**
  - **> 50% flip rate** ‚Üí Highly flaky (critical issue)
  - **30-50% flip rate** ‚Üí Moderately flaky (needs attention)
  - **10-30% flip rate** ‚Üí Slightly flaky (monitor)
  - **< 10% flip rate** ‚Üí Stable (acceptable variance)

  **Detection Algorithm:**

  ```
  For each unique test found in git notes:

  1. Build history across last N commits:
     Test: "ExpenseTracker ‚Ä∫ should add expense"
     History: ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚ùå ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚ùå

  2. Count transitions (pass‚Üífail or fail‚Üípass):
     ‚úÖ‚Üí‚ùå (1), ‚ùå‚Üí‚úÖ (2), ‚úÖ‚Üí‚ùå (3), ‚ùå‚Üí‚úÖ (4), ‚úÖ‚Üí‚ùå (5)
     Flips: 5

  3. Calculate flip rate:
     Flip rate = 5 flips / 9 transitions = 55.6%

  4. Classify:
     55.6% > 50% ‚Üí HIGHLY FLAKY
  ```

  **Report Format:**

  ```markdown
  ## Flaky Tests Detected ‚ö†Ô∏è

  ### 1. ExpenseTracker ‚Ä∫ should add expense with Enter key [chromium]
  **Flakiness**: 55.6% (5 flips in 10 runs)
  **Pattern**: ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚ùå ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚ùå
  **First flaky**: 3 days ago (commit abc123)
  **Severity**: üî¥ CRITICAL (>50%)

  **Common Error When Failing**: Timeout waiting for button

  **Recommendations**:
  - Review timeout handling in test
  - Check for race conditions in button rendering
  - Add explicit waits for button visibility
  - Consider increasing timeout or adding retry logic

  **Fix Priority**: HIGH - Blocks CI reliability

  ---

  ### 2. CurrencySelector ‚Ä∫ Visual snapshot [webkit]
  **Flakiness**: 33.3% (3 flips in 10 runs)
  **Pattern**: ‚úÖ ‚úÖ ‚ùå ‚úÖ ‚ùå ‚úÖ ‚ùå ‚úÖ ‚úÖ ‚úÖ
  **First flaky**: 5 days ago (commit def456)
  **Severity**: üü° MODERATE (30-50%)

  **Common Error When Failing**: Visual snapshot pixels differ

  **Recommendations**:
  - May be environmental (font rendering, OS differences)
  - Visual tests should only run in consistent CI environment
  - Check if snapshots are Linux-based (CI snapshots only)

  **Fix Priority**: MEDIUM - Monitor for degradation
  ```

  **Key Insights:**

  - **Flaky tests are different from bugs**: Bugs fail consistently, flaky tests fail intermittently
  - **Flakiness indicates test quality issues**: Timing, race conditions, dependencies
  - **High flip rate = urgent**: Tests with >50% flip rate destroy CI trust
  - **Track over time**: New flakiness might indicate environmental changes

  ### Feature 2: Failure Trend Analysis

  Identify when tests started failing and track degradation/improvement over time.

  **What it tracks:**
  - First failure occurrence (when did it start failing?)
  - Failure duration (how long has it been failing?)
  - Failure frequency (fails in X% of recent runs)
  - Trend direction (getting worse, stable, improving)
  - Recent vs historical comparison

  **Workflow** (uses **git-notes-helper** Operations 1, 6, 7):

  **Reference**: See `.claude/skills/git-notes-helper/helper.yaml` ‚Üí Operation 7 (Historical Analysis) ‚Üí Pattern 3

  ```bash
  # Step 1: Fetch git notes for historical analysis (Operation 1)
  git fetch origin refs/notes/ci/e2e-failures:refs/notes/ci/e2e-failures

  # Step 2: Find first failure (Operation 7 - Pattern 3: Find First Failure)
  # Walk backwards through commits until test passes or history exhausted

  # Step 3: Calculate time-based metrics
  # - Days since first failure (use Operation 6 for commit timestamps)
  # - Failure rate in last 7 days vs last 30 days
  # - Pass rate trend (improving, degrading, stable)

  # Step 4: Determine trend direction
  # Recent 5 runs: ‚ùå ‚ùå ‚ùå ‚ùå ‚ùå ‚Üí Consistently failing (stable bug)
  # Recent 5 runs: ‚úÖ ‚úÖ ‚úÖ ‚ùå ‚ùå ‚Üí Recently broke (regression)
  # Recent 5 runs: ‚ùå ‚ùå ‚ùå ‚úÖ ‚úÖ ‚Üí Recently fixed (recovering)
  # Recent 5 runs: ‚ùå ‚úÖ ‚ùå ‚úÖ ‚ùå ‚Üí Flaky (see Feature 1)
  ```

  **Detection Logic:**

  ```
  For currently failing test:

  1. Find first failure commit:
     - Walk backwards: HEAD, HEAD~1, HEAD~2, ...
     - Check each commit's git note
     - Stop when test passes or 30 days reached

  2. Calculate metrics:
     - Duration: commits_since_first_failure
     - Time: timestamp_now - timestamp_first_failure
     - Recent rate: failures_last_5 / 5
     - Historical rate: failures_last_20 / 20

  3. Classify trend:
     if recent_rate > historical_rate:
       "DEGRADING" (getting worse)
     elif recent_rate < historical_rate:
       "IMPROVING" (getting better)
     else:
       "STABLE" (consistent failure)
  ```

  **Simplified Commands:**

  ```bash
  # Find when test first failed (walk backwards)
  for commit in $(git log --oneline -30 --format="%H"); do
    if git notes --ref=ci/e2e-failures show "$commit" 2>/dev/null | \
       grep -q "test_name = ExpenseTracker ‚Ä∫ should add expense"; then
      echo "Failed at: $commit"
    else
      echo "Passed at: $commit (first failure after this)"
      break
    fi
  done

  # Get commit metadata for first failure
  git show --no-patch --format="%h: %s (%ar, %cd)" <first-failure-commit>

  # Calculate failure rate in last N commits
  total=0
  failed=0
  for commit in $(git log --oneline -10 --format="%H"); do
    total=$((total + 1))
    if git notes --ref=ci/e2e-failures show "$commit" 2>/dev/null | \
       grep -q "test_name = ExpenseTracker ‚Ä∫ should add expense"; then
      failed=$((failed + 1))
    fi
  done
  echo "Failure rate: $failed / $total"
  ```

  **Report Format:**

  ```markdown
  ## Failure Trend Analysis üìà

  ### 1. ExpenseTracker ‚Ä∫ should add expense with Enter key [chromium]

  **Current Status**: ‚ùå FAILING

  **Trend Metrics:**
  - **First Failed**: 3 days ago (commit abc123 - "Add edit button")
  - **Failure Duration**: 3 days (15 commits)
  - **Recent Failure Rate**: 80% (4/5 in last 5 runs)
  - **Historical Failure Rate**: 60% (12/20 in last 20 runs)
  - **Trend**: üî¥ DEGRADING (getting worse)

  **Failure History:**
  ```
  Recent (last 10 commits, newest first):
  abc123  ‚ùå  1h ago   "Refactor expense form"
  def456  ‚ùå  3h ago   "Update button styles"
  ghi789  ‚úÖ  5h ago   "Fix typo"
  jkl012  ‚ùå  8h ago   "Add validation"
  mno345  ‚ùå  12h ago  "Update deps"
  pqr678  ‚úÖ  1d ago   "Lint fixes"
  stu901  ‚ùå  1d ago   "Add edit button" ‚Üê FIRST FAILURE
  vwx234  ‚úÖ  2d ago   "Working state"
  yza567  ‚úÖ  2d ago   "Feature complete"
  bcd890  ‚úÖ  3d ago   "Initial impl"
  ```

  **Analysis:**
  - Test was stable before commit stu901 (worked for 20+ commits)
  - Started failing after "Add edit button" feature
  - Failure rate increased from 60% ‚Üí 80% (degrading)
  - Likely introduced by code in stu901 or related changes

  **Root Cause Hypothesis:**
  ```bash
  # Review changes in first failing commit
  git show stu901 -- packages/frontend/src/components/ExpenseForm.svelte

  # Check for button-related changes
  git diff vwx234 stu901 -- packages/frontend/src/
  ```

  **Recommendations:**
  1. **Immediate**: Review commit stu901 for button rendering changes
  2. **Investigate**: Check if "Add edit button" feature conflicts with test
  3. **Consider**: Revert stu901 temporarily to verify it's the culprit
  4. **Fix**: Address root cause identified in first failing commit

  **Fix Priority**: üî¥ HIGH - Degrading trend, blocking merges for 3 days

  ---

  ### 2. CurrencySelector ‚Ä∫ Visual snapshot [webkit]

  **Current Status**: ‚ùå FAILING

  **Trend Metrics:**
  - **First Failed**: 1 day ago (commit xyz789 - "Update font sizes")
  - **Failure Duration**: 1 day (5 commits)
  - **Recent Failure Rate**: 40% (2/5 in last 5 runs)
  - **Historical Failure Rate**: 20% (2/10 in last 10 runs)
  - **Trend**: üü° STABLE (consistent failure rate)

  **Failure History:**
  ```
  Recent (last 10 commits):
  abc123  ‚úÖ  1h ago
  def456  ‚ùå  3h ago  ‚Üê Current failure
  ghi789  ‚úÖ  5h ago
  jkl012  ‚ùå  8h ago
  mno345  ‚úÖ  12h ago
  pqr678  ‚úÖ  1d ago
  stu901  ‚úÖ  1d ago
  vwx234  ‚úÖ  1d ago
  yza567  ‚ùå  1d ago  ‚Üê FIRST FAILURE (commit xyz789)
  bcd890  ‚úÖ  2d ago
  ```

  **Analysis:**
  - New failure (only 1 day old)
  - Failure rate relatively low (40%)
  - May be flaky rather than deterministic bug
  - Visual test - could be font rendering issue

  **Recommendations:**
  1. Check if failure is flaky (see Flaky Test Detection)
  2. Review font size changes in xyz789
  3. Verify visual snapshots are Linux-based (CI only)
  4. Consider updating snapshots if change is intentional

  **Fix Priority**: üü° MEDIUM - Recent issue, monitor for 1-2 more days
  ```

  **Key Insights:**

  - **Stable failures = bugs**: High consistent failure rate indicates real bug
  - **Recent failures = regressions**: New failures point to recent code changes
  - **Degrading trends = urgent**: Increasing failure rate needs immediate attention
  - **Duration matters**: Long-failing tests block team velocity
  - **First failure commit = root cause**: Start investigation here

  ### Feature 3: Blame Integration

  Connect test failures to specific code changes, authors, and commits for accountability.

  **What it provides:**
  - Commit author and timestamp
  - Full commit message and context
  - Files changed in problematic commit
  - Git diff of relevant files
  - Direct links to lines of code (file:line format)

  **Workflow** (uses **git-notes-helper** Operation 6):

  **Reference**: See `.claude/skills/git-notes-helper/helper.yaml` ‚Üí Operation 6 (Get Commit Context)

  ```bash
  # Step 1: Get first failure commit (from Feature 2)
  FIRST_FAIL_COMMIT="stu901ab"

  # Step 2: Get commit metadata (Operation 6)
  git show --no-patch --format=full $FIRST_FAIL_COMMIT
  # Or: git log --format="%an <%ae>%n%ar%n%n%s%n%n%b" -1 $FIRST_FAIL_COMMIT

  # Step 3: Get files changed (Operation 6)
  git diff-tree --no-commit-id --name-only -r $FIRST_FAIL_COMMIT
  # Or with status: git diff-tree --no-commit-id --name-status -r $FIRST_FAIL_COMMIT

  # Step 4: Get detailed diff for relevant files (Operation 6)
  git show $FIRST_FAIL_COMMIT -- packages/frontend/src/

  # Step 5: Find blame for specific lines (Operation 6)
  git blame -L <start>,<end> <file> $FIRST_FAIL_COMMIT
  ```

  **Detection Logic:**

  ```
  For failing test with identified first failure commit:

  1. Extract commit metadata:
     - Author: git log --format="%an <%ae>"
     - Date: git log --format="%ar (%ad)"
     - Message: git log --format="%s%n%n%b"

  2. Identify relevant files:
     - Match test file path to source files
     - Example: tests/e2e/expense-workflow.spec.ts
       ‚Üí packages/frontend/src/components/ExpenseForm.svelte

  3. Show contextual diff:
     - Full diff of identified files
     - Highlight added/removed lines
     - Focus on test-related changes

  4. Provide investigation commands:
     - git show <commit>
     - git diff <commit>~1 <commit>
     - git blame <file>
  ```

  **Simplified Commands:**

  ```bash
  # Get commit author and message
  git log --format="%an <%ae>%n%ar%n%n%s%n%n%b" -1 <commit>

  # Get files changed in commit
  git diff-tree --no-commit-id --name-status -r <commit>

  # Show full diff for specific file
  git show <commit> -- path/to/file.ts

  # Get blame for specific line range
  git blame -L 50,60 packages/frontend/src/components/ExpenseForm.svelte <commit>

  # Find all commits touching a file in range
  git log --oneline -10 -- packages/frontend/src/components/ExpenseForm.svelte
  ```

  **Report Format:**

  ```markdown
  ## Blame Integration üîç

  ### 1. ExpenseTracker ‚Ä∫ should add expense with Enter key [chromium]

  **First Failure Commit**: stu901ab

  **Commit Details:**
  ```
  Author: John Doe <john@example.com>
  Date: 3 days ago (2025-10-23 14:30:00)
  Commit: stu901ab

  feat(frontend): Add edit button to expense items

  - Add edit button with icon
  - Wire up edit handler
  - Update button styles

  Refs #42
  ```

  **Files Changed** (4 files):
  ```
  M  packages/frontend/src/components/ExpenseForm.svelte
  M  packages/frontend/src/components/ExpenseList.svelte
  A  packages/frontend/src/components/EditButton.svelte
  M  packages/frontend/src/styles/buttons.css
  ```

  **Relevant Diff** (ExpenseForm.svelte):
  ```diff
  packages/frontend/src/components/ExpenseForm.svelte

  @@ -45,7 +45,9 @@
   </script>

   <div class="form-container">
  -  <button type="submit">Add</button>
  +  <button class="edit-button" onclick={handleEdit}>Edit</button>
  +  <button type="submit" bind:this={submitButton}>Add</button>
  +  <button class="cancel-button" onclick={handleCancel}>Cancel</button>
   </div>
  ```

  **Blame Analysis**:
  ```
  ExpenseForm.svelte:47-49 (stu901ab - John Doe - 3 days ago)
  + <button class="edit-button" onclick={handleEdit}>Edit</button>
  + <button type="submit" bind:this={submitButton}>Add</button>
  + <button class="cancel-button" onclick={handleCancel}>Cancel</button>
  ```

  **Root Cause Analysis:**
  - **What changed**: Added 2 new buttons (Edit, Cancel)
  - **Impact**: Test selector `getByRole('button', { name: 'Add' })` now ambiguous
  - **Why it broke**: Multiple buttons with same role, selector timing changed
  - **Responsibility**: John Doe (john@example.com)

  **Investigation Commands:**
  ```bash
  # View full commit
  git show stu901ab

  # Compare before/after
  git diff stu901ab~1 stu901ab -- packages/frontend/src/components/ExpenseForm.svelte

  # See all button-related changes
  git log --oneline -5 -S "button" -- packages/frontend/src/components/ExpenseForm.svelte

  # Check test file for selector
  grep -n "getByRole.*button" tests/e2e/expense-workflow.spec.ts
  ```

  **Fix Responsibility:**
  - **Primary**: John Doe (introduced change)
  - **Secondary**: Test author (should update test for new buttons)
  - **Suggested Fix**: Use more specific selector or add data-testid

  **Communication:**
  ```
  @john: Your commit stu901ab ("Add edit button") introduced a test failure in
  ExpenseTracker ‚Ä∫ should add expense. The new Edit button affects the test's
  button selector. Can you review and update the test selector to be more specific?

  Test error: Timeout waiting for getByRole('button', { name: 'Add' })
  Suggested fix: Use button[type="submit"] or add data-testid="add-button"
  ```

  ---

  ### 2. CurrencySelector ‚Ä∫ Visual snapshot [webkit]

  **First Failure Commit**: yza567cd

  **Commit Details:**
  ```
  Author: Jane Smith <jane@example.com>
  Date: 1 day ago (2025-10-25 10:15:00)
  Commit: yza567cd

  style(frontend): Update font sizes for better readability

  - Increase base font from 14px to 16px
  - Update heading hierarchy
  - Adjust spacing accordingly
  ```

  **Files Changed** (2 files):
  ```
  M  packages/frontend/src/styles/typography.css
  M  packages/frontend/src/components/CurrencySelector.svelte
  ```

  **Relevant Diff** (CurrencySelector.svelte):
  ```diff
  packages/frontend/src/components/CurrencySelector.svelte

  @@ -10,7 +10,7 @@
   </script>

   <style>
  -  font-size: 14px;
  +  font-size: 16px;
     font-weight: 500;
   </style>
  ```

  **Root Cause Analysis:**
  - **What changed**: Font size increased 14px ‚Üí 16px
  - **Impact**: Visual snapshot pixels differ (intentional design change)
  - **Why it "broke"**: Snapshots not updated after visual change
  - **Responsibility**: Jane Smith (janesmith@example.com)

  **Fix Action Required:**
  ```
  @jane: Your commit yza567cd changed font sizes, which affected visual snapshots.
  This appears to be an intentional design change. Please update snapshots:

  Option 1: Add [update-snapshots] to commit message
  Option 2: Comment /update-snapshots on PR
  Option 3: Manual: npm run test:e2e:docker:update-snapshots

  Note: Visual snapshots are only updated in CI (Linux environment).
  ```
  ```

  **Key Insights:**

  - **Blame != punishment**: Use for context and communication, not finger-pointing
  - **Author accountability**: Help authors understand impact of their changes
  - **Faster resolution**: Direct communication with commit author accelerates fixes
  - **Code ownership**: Identify maintainers for specific components
  - **Historical context**: Understand why changes were made (commit message)

  ### Feature 4: Comparison Reports

  Compare current test results with previous run to identify changes (new failures, fixes).

  **What it shows:**
  - New failures (were passing, now failing) - REGRESSIONS
  - Fixed tests (were failing, now passing) - IMPROVEMENTS
  - Still failing (continue to fail) - CHRONIC ISSUES
  - Still passing (continue to pass) - STABLE
  - Summary of changes since last run

  **Workflow** (uses **git-notes-helper** Operation 8):

  **Reference**: See `.claude/skills/git-notes-helper/helper.yaml` ‚Üí Operation 8 (Compare Two Commits)

  ```bash
  # Step 1: Get current and previous commit hashes
  CURRENT=$(git rev-parse HEAD)
  PREVIOUS=$(git rev-parse HEAD~1)

  # Step 2: Get test results for both (Operation 3)
  git notes --ref=ci/e2e-failures show $CURRENT
  git notes --ref=ci/e2e-failures show $PREVIOUS

  # Step 3: Extract test names from both (Operation 5)
  # Current failures
  git notes --ref=ci/e2e-failures show $CURRENT | grep "^test_name" | cut -d'=' -f2

  # Previous failures
  git notes --ref=ci/e2e-failures show $PREVIOUS | grep "^test_name" | cut -d'=' -f2

  # Step 4: Compare and categorize (Operation 8 pattern)
  # New failures: In current but NOT in previous
  # Fixed tests: In previous but NOT in current
  # Still failing: In both current AND previous
  ```

  **Detection Logic:**

  ```
  Compare current vs previous test runs:

  1. Extract test lists:
     current_failures = [test1, test2, test3]
     previous_failures = [test2, test4]

  2. Categorize changes:
     new_failures = current - previous = [test1, test3]
     fixed_tests = previous - current = [test4]
     still_failing = current ‚à© previous = [test2]

  3. Calculate metrics:
     total_current = current_failures.length
     total_previous = previous_failures.length
     change_delta = total_current - total_previous
     improvement_rate = fixed_tests.length / (total_previous || 1)
  ```

  **Simplified Commands:**

  ```bash
  # Get current failures
  git notes --ref=ci/e2e-failures show HEAD | \
    grep "^test_name" | cut -d'=' -f2 | sort > current_failures.txt

  # Get previous failures
  git notes --ref=ci/e2e-failures show HEAD~1 | \
    grep "^test_name" | cut -d'=' -f2 | sort > previous_failures.txt

  # Find new failures (in current, not in previous)
  comm -23 current_failures.txt previous_failures.txt

  # Find fixed tests (in previous, not in current)
  comm -13 current_failures.txt previous_failures.txt

  # Find still failing (in both)
  comm -12 current_failures.txt previous_failures.txt

  # Cleanup
  rm current_failures.txt previous_failures.txt
  ```

  **Report Format:**

  ```markdown
  ## Comparison Report: Current vs Previous Run üìä

  **Current Commit**: abc123de (1h ago)
  **Previous Commit**: xyz789fg (3h ago)
  **Time Between Runs**: 2 hours

  ---

  ### Summary

  | Category | Count | Change |
  |----------|-------|--------|
  | **Total Tests** | 42 | No change |
  | **Total Failures** | 4 | +2 (worse) üî¥ |
  | **Total Passing** | 38 | -2 (worse) |
  | **Pass Rate** | 90.5% | -4.8% üìâ |

  **Status**: üî¥ DEGRADED (more failures than last run)

  ---

  ### üÜï New Failures (2 tests)

  Tests that were **passing** in previous run, now **failing**:

  #### 1. ExpenseTracker ‚Ä∫ should delete expense [chromium]
  - **Status**: ‚úÖ ‚Üí ‚ùå (REGRESSION)
  - **Error**: Timeout waiting for delete button
  - **First Failed**: This commit (abc123de)
  - **Likely Cause**: Recent code change in this commit

  **Investigation**:
  ```bash
  # What changed between runs?
  git diff xyz789fg abc123de -- packages/frontend/src/components/ExpenseList.svelte
  ```

  #### 2. CurrencySelector ‚Ä∫ should switch currencies [webkit]
  - **Status**: ‚úÖ ‚Üí ‚ùå (REGRESSION)
  - **Error**: Expected USD, got EUR
  - **First Failed**: This commit (abc123de)
  - **Likely Cause**: State management change

  **Investigation**:
  ```bash
  # Check for currency-related changes
  git diff xyz789fg abc123de -- packages/frontend/src/components/CurrencySelector.svelte
  ```

  ---

  ### ‚úÖ Fixed Tests (1 test)

  Tests that were **failing** in previous run, now **passing**:

  #### 1. Onboarding ‚Ä∫ should complete flow [chromium]
  - **Status**: ‚ùå ‚Üí ‚úÖ (FIXED!)
  - **Was Failing For**: 2 commits (fixed in this run)
  - **Fix Commit**: abc123de
  - **Congratulations!** üéâ

  **What Fixed It?**:
  ```bash
  # Review changes that fixed the issue
  git show abc123de -- packages/frontend/src/components/Onboarding.svelte
  ```

  ---

  ### ‚ùå Still Failing (2 tests)

  Tests that **continue to fail** (failing in both runs):

  #### 1. ExpenseTracker ‚Ä∫ should add expense with Enter key [chromium]
  - **Status**: ‚ùå ‚Üí ‚ùå (CHRONIC)
  - **Failing For**: 3 days (15 commits)
  - **Failure Rate**: 80% (recent)
  - **Priority**: üî¥ HIGH (long-standing issue)

  #### 2. Visual: Currency dropdown [webkit]
  - **Status**: ‚ùå ‚Üí ‚ùå (CHRONIC)
  - **Failing For**: 1 day (5 commits)
  - **Failure Rate**: 40% (may be flaky)
  - **Priority**: üü° MEDIUM

  ---

  ### üìà Trend Analysis

  **Recent History** (last 5 runs):
  ```
  5 runs ago:  2 failures
  4 runs ago:  2 failures
  3 runs ago:  2 failures
  2 runs ago:  2 failures
  1 run ago:   2 failures ‚Üê Previous
  Current:     4 failures ‚Üê Current (WORSE)
  ```

  **Observation**: Failure count doubled in this run (2 ‚Üí 4).
  This indicates **recent regressions** introduced in commit abc123de.

  ---

  ### üéØ Action Items

  **Immediate (Fix Today)**:
  1. üî¥ Investigate new failures (ExpenseTracker delete, CurrencySelector switch)
  2. üî¥ Review commit abc123de for breaking changes
  3. üü° Consider reverting abc123de if regressions are severe

  **Short-term (This Week)**:
  1. üî¥ Fix chronic ExpenseTracker failure (failing 3 days)
  2. üü° Monitor CurrencySelector visual test (may be flaky)

  **Celebrate**:
  1. ‚úÖ Onboarding flow fixed! (was failing for 2 commits)

  ---

  ### üìã Comparison Commands

  ```bash
  # Compare full test output
  git notes --ref=ci/e2e-failures show HEAD > current.txt
  git notes --ref=ci/e2e-failures show HEAD~1 > previous.txt
  diff previous.txt current.txt

  # Find what code changed
  git diff HEAD~1 HEAD -- packages/frontend/src/

  # View commit message
  git show --no-patch HEAD
  ```
  ```

  **Key Insights:**

  - **New failures = regressions**: Immediate attention needed (broke recently)
  - **Fixed tests = wins**: Celebrate and learn what worked
  - **Still failing = chronic**: Need systematic fix, not just quick patches
  - **Trend direction matters**: One bad run vs consistent degradation
  - **Delta analysis**: +2 failures in one commit ‚Üí investigate that commit

  ### Feature 5: Automatic Regression Detection

  **Automatic mode**: Run comparison automatically whenever analyzing failures.

  Instead of manually running Feature 4 (Comparison Reports), this feature **automatically** detects and highlights regressions at the start of every failure analysis.

  **What it does:**
  - Automatically compares current run with previous run (if git notes exist)
  - Highlights regressions (‚úÖ‚Üí‚ùå) prominently at the TOP of the report
  - Shows "REGRESSION ALERT" banner if new failures detected
  - Provides quick summary: "X new failures since last run"
  - Links regressions to likely culprit commits

  **When to use:**
  - **Always**: Run automatically during every E2E failure analysis
  - **Opt-out**: Skip if user specifically requests "no comparison"

  **Workflow** (uses **git-notes-helper** Operations 2, 3, 5, 8):

  **Reference**: See `.claude/skills/git-notes-helper/helper.yaml` ‚Üí Operation 8 (Compare Two Commits)

  ```bash
  # Step 1: Check if previous commit has E2E notes (Operation 2)
  PREV_COMMIT=$(git rev-parse HEAD~1)
  if git notes --ref=ci/e2e-failures show $PREV_COMMIT &>/dev/null; then
    echo "Previous run data found - running automatic regression detection"

    # Step 2: Extract current and previous test names (Operations 3 + 5)
    CURRENT=$(git notes --ref=ci/e2e-failures show HEAD | grep "^test_name" | cut -d'=' -f2 | sort)
    PREVIOUS=$(git notes --ref=ci/e2e-failures show $PREV_COMMIT | grep "^test_name" | cut -d'=' -f2 | sort)

    # Step 3: Find new failures - regressions (Operation 8 pattern)
    NEW_FAILURES=$(comm -23 <(echo "$CURRENT") <(echo "$PREVIOUS"))

    # Step 4: Count regressions
    REGRESSION_COUNT=$(echo "$NEW_FAILURES" | grep -c .)

    # Step 5: Show alert if regressions found
    if [ $REGRESSION_COUNT -gt 0 ]; then
      echo "‚ö†Ô∏è  REGRESSION ALERT: $REGRESSION_COUNT new failures detected!"
    fi
  else
    echo "No previous run data - skipping regression detection"
  fi
  ```

  **Report Format (Automatic)**:

  ```markdown
  === E2E TEST FAILURE ANALYSIS ===

  ## ‚ö†Ô∏è  REGRESSION ALERT

  **Status**: üî¥ NEW FAILURES DETECTED
  **Regressions**: 2 tests that were passing now fail
  **Likely Culprit**: Commit abc123de (1h ago)

  ### New Failures (‚úÖ‚Üí‚ùå)

  1. **ExpenseTracker ‚Ä∫ should delete expense [chromium]**
     - **Previously**: ‚úÖ PASSING (last 10 runs)
     - **Now**: ‚ùå FAILING (timeout)
     - **First Failed**: This commit (abc123de)
     - **Action**: REVERT or FIX immediately

  2. **CurrencySelector ‚Ä∫ should switch currencies [webkit]**
     - **Previously**: ‚úÖ PASSING (last 8 runs)
     - **Now**: ‚ùå FAILING (assertion)
     - **First Failed**: This commit (abc123de)
     - **Action**: Review state management changes

  ---

  **Quick Fix Commands**:
  ```bash
  # Revert the problematic commit
  git revert abc123de

  # OR investigate changes
  git show abc123de

  # OR run tests locally to reproduce
  npm run test:e2e:docker
  ```

  ---

  [Rest of failure analysis report continues...]
  ```

  **Integration with Other Features**:

  - **Feature 2 (Trend Analysis)**: Regressions trigger trend analysis automatically
  - **Feature 3 (Blame Integration)**: Show author of culprit commit
  - **Feature 4 (Comparison Reports)**: Full comparison available on request

  **Benefits**:

  1. **Immediate visibility**: Regressions shown first, not buried in report
  2. **No manual comparison**: Automatically runs every time
  3. **Actionable alerts**: Clear "what broke" + "who broke it" + "how to fix"
  4. **Prevents regression blindness**: Always know if tests just started failing

  **Example (Automatic Workflow)**:

  ```
  User: "E2E tests failed, what's wrong?"

  Skill (automatically):
  1. Fetch git notes for HEAD
  2. Check if notes exist for HEAD~1
  3. If yes: Run regression detection
  4. If regressions found: Show REGRESSION ALERT at top
  5. Continue with normal failure analysis
  ```

  **Detection Criteria**:

  A test is a **regression** if:
  - NOT in previous run's failure list (was passing)
  - IN current run's failure list (now failing)
  - Status change: ‚úÖ‚Üí‚ùå

  **Regression Severity**:

  - **CRITICAL**: >5 new failures in one commit
  - **HIGH**: 3-5 new failures
  - **MEDIUM**: 1-2 new failures
  - **INFO**: 0 new failures (but still have failures)

  **Output Priority**:

  ```
  1. REGRESSION ALERT (if any new failures)
  2. Individual failure details
  3. Fix recommendations
  4. Full comparison report (on request)
  ```

  **Automatic vs Manual Mode**:

  - **Automatic** (default): Always check for regressions, show alert if found
  - **Manual**: User explicitly requests comparison with `Feature 4` commands
  - **Quiet**: User requests "no comparison" to skip regression detection

examples:
  timeout_failure:
    scenario: "Test times out waiting for button"
    test_file: "tests/e2e/expense-workflow.spec.ts"
    test_name: "ExpenseTracker ‚Ä∫ should add expense with Enter key"
    browser: "chromium"
    error: "Timeout 5000ms exceeded waiting for getByRole('button', { name: 'Add' })"

    analysis_output: |
      === E2E TEST FAILURE ANALYSIS ===

      ## Summary
      - **Total Tests**: 42
      - **Passed**: 41 ‚úÖ
      - **Failed**: 1 ‚ùå
      - **Pass Rate**: 97.6%

      ## Failed Tests

      ### 1. ExpenseTracker ‚Ä∫ should add expense with Enter key [chromium]
      **File**: `tests/e2e/expense-workflow.spec.ts:15`
      **Error Type**: Timeout
      **Duration**: 5000ms

      **Error Message**:
      ```
      Timeout 5000ms exceeded.
      waiting for getByRole('button', { name: 'Add' })

      Call log:
        - locator.click()
        - waiting for getByRole('button', { name: 'Add' })
      ```

      **Artifacts**:
      - üì∏ Screenshot: `test-results/expense-workflow-chromium/test-failed-1.png`
      - üé• Video: `test-results/expense-workflow-chromium/video.webm`
      - üîç Trace: `test-results/expense-workflow-chromium/trace.zip`

      **Fix Recommendations**:
      1. **Check button selector**: Verify button with text "Add" exists in ExpenseForm
         ```bash
         git diff HEAD~1 -- packages/frontend/src/components/ExpenseForm.svelte
         ```
      2. **Check button visibility**: Ensure button isn't hidden by CSS or disabled
      3. **Review component logic**: Check if conditional rendering affects button
      4. **Run test locally**:
         ```bash
         npx playwright test expense-workflow --project=chromium --debug
         ```

      ## Quick Fixes
      - Check if button text changed from "Add" to something else
      - Verify ExpenseForm renders the submit button correctly
      - Review recent changes to ExpenseForm.svelte

  visual_regression:
    scenario: "Visual snapshot comparison fails"
    test_file: "tests/visual/currency-selector.spec.ts"
    test_name: "CurrencySelector ‚Ä∫ Visual: Currency dropdown"
    browser: "webkit"
    error: "Screenshot comparison failed: 127 pixels (0.05%) differ"

    analysis_output: |
      === E2E TEST FAILURE ANALYSIS ===

      ## Summary
      - **Total Tests**: 8
      - **Passed**: 7 ‚úÖ
      - **Failed**: 1 ‚ùå
      - **Pass Rate**: 87.5%

      ## Failed Tests

      ### 1. CurrencySelector ‚Ä∫ Visual: Currency dropdown [webkit]
      **File**: `tests/visual/currency-selector.spec.ts:10`
      **Error Type**: Visual Regression
      **Duration**: 1250ms

      **Error Message**:
      ```
      Screenshot comparison failed:

      127 pixels (0.05% of all pixels) differ

      Expected: tests/visual/currency-selector.spec.ts-snapshots/currency-selector-webkit-linux.png
      Received: test-results/visual-currency-selector-webkit/currency-selector-actual.png
      Diff: test-results/visual-currency-selector-webkit/currency-selector-diff.png
      ```

      **Artifacts**:
      - üì∏ Expected: `tests/visual/currency-selector.spec.ts-snapshots/currency-selector-webkit-linux.png`
      - üì∏ Actual: `test-results/visual-currency-selector-webkit/currency-selector-actual.png`
      - üì∏ Diff: `test-results/visual-currency-selector-webkit/currency-selector-diff.png`

      **Fix Recommendations**:
      1. **View diff image**: Open diff.png to see exactly what changed
      2. **Check CSS changes**:
         ```bash
         git diff HEAD~1 -- packages/frontend/src/components/CurrencySelector.svelte
         git diff HEAD~1 -- '*.css' '*.svelte'
         ```
      3. **If change is intentional**: Update snapshots
         ```bash
         # Add to commit message:
         git commit -m "feat(frontend): Update currency selector style [update-snapshots]"
         ```
      4. **If change is unintentional**: Investigate CSS regression

      ## Quick Fixes
      - Review diff image to understand the visual change
      - If styling change was intentional, update snapshots with [update-snapshots]
      - If not intentional, revert CSS changes causing the difference

  multiple_failures:
    scenario: "Multiple tests fail across different error types"

    analysis_output: |
      === E2E TEST FAILURE ANALYSIS ===

      ## Summary
      - **Total Tests**: 42
      - **Passed**: 38 ‚úÖ
      - **Failed**: 4 ‚ùå
      - **Pass Rate**: 90.5%

      ## Failed Tests

      ### 1. ExpenseTracker ‚Ä∫ should add expense [chromium]
      **Error Type**: Timeout
      **File**: `tests/e2e/expense-workflow.spec.ts:15`

      **Error**: Timeout waiting for getByRole('button', { name: 'Add' })

      **Artifacts**: üì∏ Screenshot | üé• Video | üîç Trace

      **Fix**: Check button selector, verify button visibility

      ---

      ### 2. CurrencySelector ‚Ä∫ Visual snapshot [webkit]
      **Error Type**: Visual Regression
      **File**: `tests/visual/currency-selector.spec.ts:10`

      **Error**: 127 pixels differ from expected screenshot

      **Artifacts**: üì∏ Diff Image | üì∏ Expected | üì∏ Actual

      **Fix**: Review CSS changes, update snapshots if intentional

      ---

      ### 3. Onboarding ‚Ä∫ should complete onboarding flow [chromium]
      **Error Type**: Assertion
      **File**: `tests/e2e/onboarding.spec.ts:25`

      **Error**: Expected URL to be '/expense-tracker', received '/onboarding'

      **Artifacts**: üì∏ Screenshot | üé• Video

      **Fix**: Check navigation logic, verify routing conditions

      ---

      ### 4. LocalStorageViewer ‚Ä∫ should display expenses [webkit]
      **Error Type**: Assertion
      **File**: `tests/e2e/local-storage-viewer.spec.ts:18`

      **Error**: Expected 3 expense items, found 0

      **Artifacts**: üì∏ Screenshot

      **Fix**: Verify localStorage state, check data persistence

      ## Quick Fixes

      **Immediate Actions**:
      1. Fix button selector issue in ExpenseTracker (timeout)
      2. Review onboarding navigation logic (assertion)
      3. Investigate localStorage persistence (assertion)
      4. Update visual snapshots if CSS change was intentional

      **Debugging Commands**:
      ```bash
      # Run failed tests in UI mode
      npm run test:e2e:ui --workspace=frontend

      # Run specific test
      npx playwright test expense-workflow --project=chromium --debug

      # Update snapshots (if visual change is intentional)
      npm run test:e2e:docker:update-snapshots
      ```

tips:
  - "Reference git-notes-helper skill for all git notes operations"
  - "Use namespace: `ci/e2e-failures` for all E2E failure notes"
  - "Follow git-notes-helper best practices for parsing and historical analysis"
  - "Always check git notes first (fastest), fall back to test-results/ for local analysis"
  - "Look for patterns in error messages to categorize failures quickly"
  - "Visual regressions often indicate unintentional CSS changes"
  - "Timeout errors usually mean selector changed or element is hidden"
  - "Browser-specific failures suggest rendering or API differences"
  - "Use Phase 3 features (Flaky Detection, Trend Analysis) for historical insights"
  - "Automatic Regression Detection runs by default - saves time identifying new failures"
  - "Screenshot artifacts are essential for visual debugging"
  - "Trace files provide the most comprehensive debugging information"

output_format: |
  Present analysis in clear sections:
  1. Summary statistics (total, passed, failed, pass rate)
  2. Failed test details (name, error, artifacts, recommendations)
  3. Quick fixes section (immediate actions)
  4. Debugging commands (local reproduction steps)

  Use visual indicators:
  - ‚úÖ for passed tests
  - ‚ùå for failed tests
  - üì∏ for screenshots
  - üé• for videos
  - üîç for traces
  - ‚ö†Ô∏è for warnings/browser-specific issues

common_issues:
  no_test_results_found:
    symptom: "test-results/ directory is empty or doesn't exist"
    solution: |
      Test results not available. Possible causes:
      1. Tests haven't been run yet ‚Üí Run: npm run test:e2e:docker
      2. Tests passed (no failures to analyze) ‚Üí Check git status
      3. Results were cleaned up ‚Üí Re-run tests to regenerate

  artifacts_not_found:
    symptom: "Screenshots/videos referenced but files don't exist"
    solution: |
      Artifacts may have been cleaned up or test was skipped.
      To regenerate:
      - Run failed test again: npx playwright test {test-name}
      - Ensure screenshot/video settings enabled in playwright.config.ts

  ci_vs_local_differences:
    symptom: "Tests pass locally but fail in CI"
    causes:
      - "Environment differences (Linux CI vs macOS/Windows local)"
      - "Visual snapshots are Linux-based (must update in CI)"
      - "Timing differences (CI may be slower)"
      - "Different browser versions"
    solution: |
      For visual tests: Always update snapshots via CI workflow
      For other failures: Check environment-specific issues (TEST_ENV variable)
